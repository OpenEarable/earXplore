"Column","Explanation"
"ID", "Unique Identifier for each study."
"Main Author","The main author of the paper, written as in an in-text citation."
"Year","Publication year of the study."
"Location","The specific location(s) on the body where the interactions with the earable device occur."
"Input Body Part","The part(s) of the body used to elicit the interactions with the earable device."
"Gesture","The specific gesture(s), movement(s), or action(s) the user must perform to initiate interactions with the earable device. Gestures only present in elicitation studies are not considered."
"Sensing_PANEL_Sensors","The specific sensor(s) the earable needs to enable (e.g., speaker for ultrasound) and/or recognize (e.g., a microphone) the interactions. Only sensors that are part of the earable."
"Sensing_PANEL_No Additional Sensing","No additional devices like smartphones, rings etc. are needed for sensing the interaction presented in the study."
"Interaction_PANEL_Number of Selected Gestures","The number of gestures selected for interaction. Gestures only present in elicitation studies are not counted. If the same gesture can be performed on different ears, it is only counted once. None-type-gestures are not considered."
"Interaction_PANEL_Resolution","Whether interactions involve a single distinct input (Semantic) or are continuous, with distinct steps (Coarse) or subtle, unnoticeable steps (Fine)Whether interactions involve a single distinct input (Semantic) or are continuous, with distinct steps (Coarse) or subtle, unnoticeable steps (Fine).."
"Interaction_PANEL_Hands-Free","Whether the hands play an active role in the interactions with the earable."
"Interaction_PANEL_Eyes-Free","Whether the eyes play an active role in the interactions with the earable (e.g., gaze direction). Visual Attention may be necessary without an active interaction role of the eyes."
"Interaction_PANEL_Possible on One Ear","Whether the interaction detection presented in the study is (also) possible using an earable that covers only one ear."
"Interaction_PANEL_Adaptation of the Interaction Detection Algorithm to User","Whether the interaction detection algorithm can be adapted or fine-tuned to an individual user."
"Interaction_PANEL_Discreetness of Interaction Techniques","Extent to which interaction techniques remain unseen, unheard, or undetectable in public settings. Excluding device design. For multiple techniques, the rating reflects the predominant level. Rated by two authors.; High: Interactions are publicly invisible, highly private, and indistinguishable from natural behaviors.; Medium: Interactions are somewhat discreet but still noticeable; observers may infer actions with moderate effort; Low: Interactions are clearly visible or audible, making user actions easily observable."
"Interaction_PANEL_Social Acceptability of Interaction Techniques","Appropriateness of interaction techniques in public settings. Excluding device design. For multiple techniques, the rating reflects the predominant level. Rated by two authors.; High: Highly subtle and socially acceptable, blending seamlessly into typical public behavior without drawing attention.; Medium: Moderately noticeable but generally acceptable in public, involving subtle gestures or actions.; Low: Highly noticeable, intrusive, or awkward, likely to attract attention or cause discomfort."
"Interaction_PANEL_Accuracy of Interaction Recognition","The systemâ€™s ability to accurately detect and interpret interactions, considering only the most basic reported condition and setting (e.g., sitting in a lab) for consistency. Only applies to studies reporting accuracies.; High: Demonstrates on average an overall level >= 85% for new users or a level >= 95% for users belonging to the training set.; Medium: Demonstrates on average an overall level > 75% and < 85% for new users or a level > 85% and < 95% for users belonging to the training set.; Low: Demonstrates on average an overall level < 75% for new users or a level < 85% for users belonging to the training set."
"Interaction_PANEL_Robustness of Interaction Detection","Demonstrated robustness of interaction detection performance across additional settings (e.g., a cafÃ©, outdoors) or conditions (e.g., walking, listening to music) that may cause interference, defined as an accuracy drop of less than 10%. Only applies to studies reporting accuracies.; High: Robust in both a different setting and condition.; Medium: Robust in either a different setting or condition.; Low: Not robust in either a different setting or condition."
"Study_PANEL_Elicitation Study","An elicitation study on interactions with earables has been performed."
"Study_PANEL_Usability Evaluations","Whether the usability of the interactions was assessed."
"Study_PANEL_Cognitive Ease Evaluations","Whether the cognitive ease of the interactions was assessed."
"Study_PANEL_Discreetness of Interactions Evaluations","Whether the discreetness of the interactions was assessed."
"Study_PANEL_Social Acceptability of Interactions Evaluations","Whether the social acceptability of the interactions was assessed."
"Study_PANEL_Accuracy of Interactions Evaluations","Whether the accuracy of the system's interactions detection was assessed."
"Study_PANEL_Alternative Interaction Validity Evaluations","Whether a metric other than accuracy of interaction detection was used to assess the validity of the system's interaction detection (e.g., angular error)."
"Study_PANEL_Evaluation of Different Conditions (User-Related)","The different user-related conditions the interactions were evaluated in."
"Study_PANEL_Evaluation of Different Conditions (Environment-Related)","The different environment-related conditions the interactions were evaluated in. Only deliberately induced environmental conditions not inherently part of the setting are listed, to avoid redundancy."
"Study_PANEL_Evaluation of Different Settings","The different settings the interactions were evaluated in."
"Device_PANEL_Earphone Type","The specific type of earphone used in the study."
"Device_PANEL_Development Stage","Whether a commercial earable was used or a research prototype."
"Device_PANEL_Real-Time Processing","The system is demonstrated to be able to immediately detect and respond to a userâ€™s performed interaction."
"Device_PANEL_On-Device Processing","Excluding initial training, interaction detection occurs solely on the earable itself, without external device support. Only processing directly on the device attached in, on, or the immediate vicinity of the ear qualifies, excluding smartphones or connected microcomputers." 
"Motivations_PANEL_Motivations","The motivations the authors explicitly outline for their study on interaction with earables. Only the core motivations recurring across studies were extracted, to keep the coding scheme concise and consistent. Explanations - Proof-of-Concept: Demonstrating the feasibility of a novel idea, technology, or interaction modality.; Novel Interaction Technique: Creating and/or validating a new input or output method enabled by earable technologies.; System Extension: Enhancing an existing system or concept, such as by adding new sensing modalities or features.; Performance Optimization: Improving existing solutions by increasing accuracy, robustness, efficiency, or responsiveness.; User-Centered Design: Developing the system or interaction approach based on explicitly identified user needs or user research.; Iteration on Own Prior Work: Extending or refining the authorsâ€™ own previously published research.; Societal Impact: Motivated by a larger societal goal, such as improving accessibility or health."
"Applications_PANEL_Intended Applications","The applications the authors explicitly suggest for their proposed interaction with earables."
"Keywords","The keywords selected by the authors."
"Abstract","A brief summary of the study."
"Study Link","Link to the study."

